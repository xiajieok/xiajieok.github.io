<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="https://img.econow.cn/2018/1545104669394.png"><link rel="icon" type="image/png" sizes="16x16" href="https://img.econow.cn/2018/1545104669394.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"econow.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="一、目标整理今天的目标是爬取小红书上指定笔记下的所有评论数据。"><meta property="og:type" content="article"><meta property="og:title" content="【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！"><meta property="og:url" content="https://econow.cn/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/index.html"><meta property="og:site_name" content="Medivh&#39;s castle"><meta property="og:description" content="一、目标整理今天的目标是爬取小红书上指定笔记下的所有评论数据。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://img.econow.cn/blog/1699846462459.png"><meta property="og:image" content="https://img.econow.cn/blog/1699846258815.png"><meta property="og:image" content="https://img.econow.cn/blog/1699846241920.png"><meta property="og:image" content="https://img.econow.cn/blog/1699846810764.png"><meta property="og:image" content="https://img.econow.cn/blog/1699853062807.png"><meta property="og:image" content="https://img.econow.cn/blog/1699847997111.png"><meta property="og:image" content="https://img.econow.cn/blog/1699848125908.png"><meta property="og:image" content="https://img.econow.cn/blog/1699853391435.png"><meta property="og:image" content="https://img.econow.cn/blog/1699854444787.png"><meta property="og:image" content="https://img.econow.cn/blog/1699854652024.png"><meta property="og:image" content="https://img.econow.cn/blog/1699854922304.png"><meta property="og:image" content="https://img.econow.cn/blog/1699855038573.png"><meta property="og:image" content="https://img.econow.cn/blog/1699855302613.png"><meta property="og:image" content="https://img.econow.cn/blog/1699855427961.png"><meta property="og:image" content="https://img.econow.cn/blog/1699856851194.png"><meta property="article:published_time" content="2023-11-13T03:08:46.000Z"><meta property="article:modified_time" content="2023-11-13T06:35:41.754Z"><meta property="article:author" content="medivh"><meta property="article:tag" content="Python"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://img.econow.cn/blog/1699846462459.png"><link rel="canonical" href="https://econow.cn/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://econow.cn/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/","path":"2023/11/13/【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！/","title":"【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！ | Medivh's castle</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?21ded952ca9fc25e2b0630494a17ec7f"></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Medivh's castle</p><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">数据蜘蛛工作室</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%9B%AE%E6%A0%87%E6%95%B4%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">一、目标整理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E9%80%BB%E8%BE%91%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">二、逻辑分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A5%E5%8F%A3%E5%88%86%E6%9E%90"><span class="nav-number">2.1.</span> <span class="nav-text">接口分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E6%B1%82%E5%A4%B4"><span class="nav-number">2.2.</span> <span class="nav-text">请求头</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0"><span class="nav-number">2.3.</span> <span class="nav-text">请求参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%8D%E5%BA%94%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="nav-number">2.4.</span> <span class="nav-text">响应数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B9%E8%AF%84%E8%AE%BA"><span class="nav-number">2.4.1.</span> <span class="nav-text">根评论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E7%BA%A7%E8%AF%84%E8%AE%BA%E5%92%8C%E4%BA%8C%E7%BA%A7%E5%B1%95%E5%BC%80%E8%AF%84%E8%AE%BA"><span class="nav-number">2.4.2.</span> <span class="nav-text">二级评论和二级展开评论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93"><span class="nav-number">2.4.3.</span> <span class="nav-text">简单总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.</span> <span class="nav-text">三、代码实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">四、总结</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">medivh</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">104</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">12</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">标签</span></a></div></nav></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://econow.cn/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="medivh"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Medivh's castle"><meta itemprop="description" content=""></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！ | Medivh's castle"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-11-13 11:08:46 / 修改时间：14:35:41" itemprop="dateCreated datePublished" datetime="2023-11-13T11:08:46+08:00">2023-11-13</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E4%B9%90%E8%B6%A3/" itemprop="url" rel="index"><span itemprop="name">乐趣</span></a> </span></span><span id="/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/" class="post-meta-item leancloud_visitors" data-flag-title="【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="一、目标整理"><a href="#一、目标整理" class="headerlink" title="一、目标整理"></a>一、目标整理</h2><p>今天的目标是爬取小红书上指定笔记下的所有评论数据。</p><p>以某篇举例，有2千多条评论。</p><p><img data-src="https://img.econow.cn/blog/1699846462459.png" alt="穿上了最漂亮的衣服向杀害孩子的凶手投石头"></p><p>效果如下：</p><p><img data-src="https://img.econow.cn/blog/1699846258815.png" alt="首页"></p><p><img data-src="https://img.econow.cn/blog/1699846241920.png" alt="其他页"></p><p>每条评论获取多个字段，</p><ul><li>笔记链接</li><li>页码</li><li>评论者昵称</li><li>评论者ID</li><li>评论者主页链接</li><li>评论时间</li><li>评论IP属地</li><li>评论点赞数</li><li>评论级别</li><li>评论内容</li></ul><p>而评论包含根级评论、二级评论和二级展开评论（评论回复）。</p><h2 id="二、逻辑分析"><a href="#二、逻辑分析" class="headerlink" title="二、逻辑分析"></a>二、逻辑分析</h2><h3 id="接口分析"><a href="#接口分析" class="headerlink" title="接口分析"></a>接口分析</h3><p><img data-src="https://img.econow.cn/blog/1699846810764.png" alt="抓取目标"></p><p>可以看到从这个接口中获取了我们想要的数据，左边是内容展示，右边是接口返回的相关字段。</p><h3 id="请求头"><a href="#请求头" class="headerlink" title="请求头"></a>请求头</h3><p><img data-src="https://img.econow.cn/blog/1699853062807.png" alt="请求头"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">	<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&#x27;</span>,</span><br><span class="line">	<span class="comment"># cookie需定期更换</span></span><br><span class="line">	<span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;换成自己的cookie值&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请求头这部分主要的就是UA和Cookie，其中Cookie需要定期更换，否则会出现响应数据为空的情况。</p><h3 id="请求参数"><a href="#请求参数" class="headerlink" title="请求参数"></a>请求参数</h3><p><img data-src="https://img.econow.cn/blog/1699847997111.png" alt="载荷"></p><p><img data-src="https://img.econow.cn/blog/1699848125908.png"></p><p>简单说明一下这几个参数：</p><ul><li>note_id 这个是笔记的ID，为固定值</li><li>cusor，获取第一页的时候可以为空，获取后面评论的时候需要使用，稍后再讲</li><li>top_comment_id ，同样首次请求可以为空，之后才需要。</li><li>image_scenes 固定值</li></ul><h3 id="响应数据分析"><a href="#响应数据分析" class="headerlink" title="响应数据分析"></a>响应数据分析</h3><h4 id="根评论"><a href="#根评论" class="headerlink" title="根评论"></a>根评论</h4><p>首次请求接口后会返回如下数据，接下来需要具体分析一下可能用到的字段。</p><p><img data-src="https://img.econow.cn/blog/1699853391435.png" alt="分析数据"></p><p>从图中可以很清晰的猜出部分字段的功能：</p><ul><li>comments 以list的方式存储每条评论的数据。<ul><li>content、create_time、id、ip_location、like_count、</li><li>sub_comment_count 这是个布尔类型的字段，可以猜测一下这个字段的含义，后面还有两个字段带有sub。<ul><li>根据<code>sub</code>可以联想到 <code>subsequent</code>，也就是随后的，后来的意思，所以很可能就是和二级评论或者二级展开评论有关。</li><li>count 的含义就是计数，也就是说当前这条评论有多少二级评论。</li></ul></li><li>sub_comment_cursor</li><li>sub_comment_has_more 还有更多？</li></ul></li><li>cursor 游标</li><li>has_more 还有更多？</li></ul><p>简单总结一下，我们获取到了首次请求的数据，而且获取了一些其他的字段，比如has_more很有可能就是可以继续翻页的意思。那么就是说如果这个字段一直为true，就可以一直翻页，省去了我们单独计算需要多少页的问题。那么如何拼接第二页的请求参数呢，接着看第二次请求。</p><p><img data-src="https://img.econow.cn/blog/1699854444787.png" alt="获取下一页内容"></p><p>点击加载更多后进行了第二次请求，可以看到请求参数中的<code>cursor</code>这次有了值，但是这个值<code>653b643a000000001c02bf62</code>是从哪里获取的呢？可以对照一下第一次的响应结果，看是否在里面。</p><p><img data-src="https://img.econow.cn/blog/1699854652024.png"></p><p>很明显就是第一次响应数据中的<code>cursor</code>字段的值。所以目前为止，我们有能力获取所有的根评论了。</p><h4 id="二级评论和二级展开评论"><a href="#二级评论和二级展开评论" class="headerlink" title="二级评论和二级展开评论"></a>二级评论和二级展开评论</h4><p>上一节中说到了sub相关的字段，接下来我们根据这几个字段多看几次接口请求是否能发现一些规律。所以这次我们再查看的时候肯定是要从同一个根评论去定位，而不是直接往后翻。随机找一个数量小点的评论，方便观察。</p><p><img data-src="https://img.econow.cn/blog/1699854922304.png"></p><p>这里可以看到又有一个带有<code>cursor</code>的字段，值为<code>653c85510000000025009516</code>。根据之前的经验，很有可能是进行下一次请求的游标。接下来点击展开更多回复。</p><p><img data-src="https://img.econow.cn/blog/1699855038573.png"></p><p>可以看到之前的cursor就是下次请求中cursor的值。</p><p><img data-src="https://img.econow.cn/blog/1699855302613.png"></p><p>还有一个’root_comment_id’这个可以理解为根节点的ID，就是第一次请求中的根评论的ID。</p><p><img data-src="https://img.econow.cn/blog/1699855427961.png"></p><p>至此，我们已经梳理好接口逻辑能力获取所有的评论了。</p><h4 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h4><p>获取所有评论的思路就像从树枝上摘叶子。</p><p><img data-src="https://img.econow.cn/blog/1699856851194.png"></p><h2 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h2><p>分两部分，首先是根评论获取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">resp = requests.get(note_url, headers=headers, params=params)</span><br><span class="line">data = resp.json()</span><br><span class="line">next_cursor = data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;cursor&#x27;</span>]  <span class="comment"># 翻页游标，一级评论</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;comments&#x27;</span>]:</span><br><span class="line">  <span class="comment"># 数据存储</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">int</span>(c[<span class="string">&#x27;sub_comment_count&#x27;</span>]) &gt; <span class="number">0</span>:</span><br><span class="line">    root_comment_id = c[<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line">    next_cursor_id = c[<span class="string">&#x27;sub_comment_cursor&#x27;</span>]</span><br><span class="line">    <span class="comment"># 获取二级评论或二级展开评论</span></span><br><span class="line">has_more = data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;has_more&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;:::&#x27;</span>, next_cursor, has_more)</span><br><span class="line"><span class="keyword">if</span> has_more <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;当前页<span class="subst">&#123;page&#125;</span>，下一页<span class="subst">&#123;page + <span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">  page += <span class="number">1</span>  <span class="comment"># 直接更新当前页</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>二级评论获取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">resp = requests.get(note_url, headers=headers, params=params)</span><br><span class="line"><span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    data = resp.json()</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;comments&#x27;</span>]:</span><br><span class="line">      <span class="comment"># 数据存储</span></span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;has_more&#x27;</span>]:  <span class="comment"># 如果has_more 为false说明没有数据了</span></span><br><span class="line">        <span class="keyword">return</span>  <span class="comment"># 结束递归</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        next_cursor = data[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;cursor&#x27;</span>]</span><br><span class="line">				<span class="comment"># 进行下一次请求</span></span><br><span class="line">  <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;二级评论&#x27;</span>, e)</span><br></pre></td></tr></table></figure><p>至此，爬虫代码开发完毕。</p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>思路是借鉴某位大佬的，具体代码是自己摸索中实现的。开发过程中也遇到了一定的问题，但都不重要。</p></div><footer class="post-footer"><div class="reward-container"><div>喜欢就点个赞吧！</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.jpg" alt="medivh 微信"> <span>微信</span></div><div><img src="/images/alipay.jpg" alt="medivh 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>medivh</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://econow.cn/2023/11/13/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E4%BD%BF%E7%94%A8Python%E9%87%87%E9%9B%86%E5%B0%8F%E7%BA%A2%E4%B9%A6%E7%AC%94%E8%AE%B0%E7%9A%84%E8%AF%84%E8%AE%BA%EF%BC%8C%E7%88%AC%E4%BA%8610000%E5%A4%9A%E6%9D%A1%EF%BC%8C%E5%90%AB%E5%A4%9A%E7%BA%A7%E8%AF%84%E8%AE%BA%EF%BC%81/" title="【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！">https://econow.cn/2023/11/13/【爬虫实战】使用Python采集小红书笔记的评论，爬了10000多条，含多级评论！/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a> <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2023/11/07/%E4%BD%BF%E7%94%A8Python%E5%88%B7%E6%9F%90%E5%8D%9A%E5%AE%A2%E5%B9%B3%E5%8F%B0%E7%9A%84%E9%98%85%E8%AF%BB%E9%87%8F/" rel="prev" title="使用Python刷某博客平台的阅读量"><i class="fa fa-angle-left"></i> 使用Python刷某博客平台的阅读量</a></div><div class="post-nav-item"><a href="/2023/11/15/%E3%80%90%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E3%80%91%E9%80%86%E5%90%91%E6%9F%90%E5%85%AC%E4%BC%97%E5%B9%B3%E5%8F%B0%E7%99%BB%E5%BD%95%E6%8E%A5%E5%8F%A3/" rel="next" title="【爬虫实战】逆向某公众平台登录接口">【爬虫实战】逆向某公众平台登录接口 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备17063827号-2</a></div><div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">medivh</span></div></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"g1GwilqmVAUne2tDEDncEChG-gzGzoHsz","app_key":"YB2e5dSKMmMYYCtaSzxp9fdS","server_url":"https://api.econow.cn","security":false}</script><script src="/js/third-party/statistics/lean-analytics.js"></script></body></html>